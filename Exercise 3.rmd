---
title: "Exercise 3"
output: html_document
date: "2023-05-18"
---
<!-- uses feather file -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(conflicted)
library(dplyr)
library(tidyverse)
library(lubridate)

library(gender)

```

## Open data file

I'm going to load the data I saved after the last exercise.
```{r load-data}
library(arrow)
applications <- read_feather("C:/Users/vrind/OneDrive/Desktop/Course terms/Summer Term/People Analytics/Week 2/app_data_starter.feather")

# lists all variables (columns) in the data
applications |> tbl_vars()
```

## Look at examiners demographics

The first thing to note here is that our unit of interest is an *examiner*, but our data is at the level of a *patent application*. Examiners work with many patent applications during their tenure at the USPTO. Those who have longer tenure in our sample will have worked on more applications, and so if we count the number of *records* with attributes `male` or `female`, we will overcount those who have worked there longer.

We may be better off creating a separate table---a.k.a. a *dataframe*---where there is only one record per examiner. In other words, we need to "collapse" the applications data, with multiple records per examiner, to examiner-level data, where we only have one record per individual.

```{r count-examiners}
library(dplyr)
applications %>%
  distinct(examiner_id) %>%
  count()
```

### Compare TCs by gender graphically
This is what chatGPT gave us:

```{r compare-tcs-gender}
library(dplyr)
library(ggplot2)
applications %>%
  group_by(tc, gender) %>%
  #filter(!is.na(gender)) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  ggplot(aes(x = as.factor(tc), y = n, fill = gender)) +
  geom_col(position = "dodge") +
  ylab("Examiners")
```

### Compare WGs by gender graphically
This is what chatGPT gave us:

```{r compare-WGs-gender}
library(dplyr)
library(ggplot2)
applications %>%
  mutate(wg = floor(examiner_art_unit/10)*10) %>%
  group_by(wg, gender) %>%
  #filter(!is.na(gender)) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  ggplot(aes(x = as.factor(wg), y = n, fill = gender)) +
  geom_col(position = "dodge") +
  ylab("Examiners")
```

### Compare TCs by race graphically

```{r compare-tcs-race}
library(dplyr)
library(ggplot2)
applications %>%
  group_by(tc, race) %>%
  #filter(!is.na(race)) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  ggplot(aes(x = as.factor(tc), y = n, fill = race)) +
  geom_col(position = "dodge") +
  ylab("Examiners")
```
### Compare WGs by race graphically

```{r compare-WGs-race}
library(dplyr)
library(ggplot2)
applications %>%
  mutate(wg = floor(examiner_art_unit/10)*10) %>%
  group_by(wg, race) %>%
  #filter(!is.na(gender)) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  ggplot(aes(x = as.factor(wg), y = n, fill = race)) +
  geom_col(position = "dodge") +
  ylab("Examiners")
```
### Compare TCs by tenure graphically

```{r compare-tcs-tenure}
library(dplyr)
library(ggplot2)
applications %>%
  group_by(tc, tenure_days) %>%
  #filter(!is.na(tenure_days)) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  ggplot(aes(x = as.factor(tc), y = n, fill = tenure_days)) +
  
  geom_col(position = "dodge") +
  ylab("Examiners")
```
## Tenure distribution across technology centres

```{r tenure-alt, echo=FALSE}

ggplot(applications, aes(fill = as.factor(tc), x = tenure_days)) + 
  geom_histogram(binwidth = 365) +
  # ggtitle("Tenure distribution across technology centres") +
  # xlab("Tenure (years)") +
  scale_x_continuous(labels = function(x) x / 365,
                      breaks = seq(0, max(applications$tenure_days, na.rm = TRUE), by = 365))+
  ylab("Frequency")+
  theme_minimal()+
  labs(fill = "Technology Centre")
```

## Correlations

We have tenure for each person and we want to know whether tenure is predicted by gender.

```{r correlations-gender}
library(dplyr)
examiners <- applications %>%
  group_by(examiner_id) %>%
  summarise(
    tenure = first(tenure_days), 
    gender = first(gender),
    race = first(race),
    tc = first(tc)
    )

library(broom)
fit1 <- lm(tenure ~ gender + race, data = examiners)
tidy(fit1)

fit2 <- lm(tenure ~ gender + race + tc, data = examiners)
tidy(fit2)
```


## Explaining turnover by gender
<!-- and then predicting turnover by linear model (linear regression) -->

<!-- The filing date is the date of filing the application. The appl_status_date -->
<!-- is the last date. We will get the year from the appl_status_date. -->


<!-- converting appl_status_date to date -->
```{r }
applications <- applications %>%
  mutate(appl_status_date = dmy_hms(appl_status_date))

applications <- applications %>%
  mutate(year = year(appl_status_date))
```


 <!-- Creating another table consisting of examiner ids, tc, gender, race  -->
 <!-- and min year, max year and year-left if they left before 2012 -->

``` {r}
turnover <- applications %>%
  group_by(examiner_id) %>%
  summarize(min_year = min(year), max_year = max(year), tc = first(tc), gender = first(gender), race = first(race)) %>%
  mutate(year_left = if_else(max_year<2017, max_year+1, NA_real_))
```

#picking 2013 for analysis year
```{r}
regression_data <- turnover %>%
  dplyr::filter(min_year <= 2013, year_left >= 2014 | is.na(year_left)) %>%
  mutate(left = if_else(year_left != 2014 | is.na(year_left),0,1)) %>%
   drop_na(gender)
```

<!-- number of males and females who left in 2013 -->
```{r}
regression_data %>%
  count(gender, left) %>%
  group_by(gender) %>%
  mutate(pct = n/sum(n))
```

<!-- splitting the data using the slice_sample() function: -->
```{r}
# Assuming your dataset is named "data"
set.seed(123)  # Set seed for reproducibility

# Calculate the number of rows for the training set and holdout set
total_rows <- nrow(regression_data)
train_rows <- round(0.85 * total_rows)

# Split the data into training and holdout sets
training_data <- slice_sample(regression_data, n = train_rows)
# Create a vector of randomly selected row indices for the training set
train_indices <- sample(total_rows, train_rows)
holdout_data <- regression_data[-train_indices, ]
```

<!-- Fitting the linear regression model -->
```{r}
model_training_data <- lm(data = training_data, left ~ gender + as.factor(tc))
tidy(model_training_data)
summary(model_training_data)
```


<!-- Comparing the model using r-squared method -->
The sum of squares of residuals (ss_residual) is calculated as the sum of squared differences between the actual values and the predicted values. The total sum of squares (ss_total) is computed as the sum of squared differences between the actual values and the mean of the actual values.

Finally, the R-squared value is calculated by subtracting the ratio of the sum of squares of residuals to the total sum of squares from 1. The resulting rsquared variable will contain the R-squared value, which indicates the goodness-of-fit of the linear regression model on the holdout data.
```{r}
# Assuming you have the linear regression model stored in 'model' 
# and the holdout data stored in 'holdout_data'

# Extract the dependent variable from the holdout data
holdout_actual <- holdout_data$left

# Use the model to predict values for the holdout data
holdout_predicted <- predict(model_training_data, newdata = holdout_data)

# Calculate the R-squared value
ss_residual <- sum((holdout_actual - holdout_predicted)^2)
ss_total <- sum((holdout_actual - mean(holdout_actual))^2)
rsquared <- 1 - (ss_residual / ss_total)

```
An R-squared value of 0.0014967026476731 is a very small value to correctly predict the relation between turnover rate with gender and tc. This implies that the model does not effectively capture the relationship between the independent variables and the dependent variable in the holdout data.

The model may not be able to accurately capture the underlying patterns or relationships in the data, leading to poor performance in predicting or explaining the dependent variable. SO maybe the turnover rate is not linearly dependent on gender and race.
